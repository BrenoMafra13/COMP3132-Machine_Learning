{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKQ3nHEN9kOA1Sk59OTAz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrenoMafra13/COMP3132-Machine_Learning/blob/main/assign1_Breno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student name: Breno Lopes Mafra \\\n",
        "Student ID: 101485572**"
      ],
      "metadata": {
        "id": "-fGQigb5de6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF-3tpDIX4-y",
        "outputId": "0463cbc9-99bf-44af-89dc-89a1f6f2a5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What are the dimensions of train_images, train_labels, test_images, and test_labels?**"
      ],
      "metadata": {
        "id": "3q9-hMgMZPs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_images:', train_images.shape)\n",
        "print('train_labels:', train_labels.shape)\n",
        "print('test_images:', test_images.shape)\n",
        "print('test_labels:', test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmMYhketZqYb",
        "outputId": "cb926869-bff2-406a-f3b5-b453378384e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images: (60000, 28, 28)\n",
            "train_labels: (60000,)\n",
            "test_images: (10000, 28, 28)\n",
            "test_labels: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the lengths of train_labels and test_labels?**"
      ],
      "metadata": {
        "id": "fqPmACigeEIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_labels))\n",
        "print(len(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P9bfGq0eL5Q",
        "outputId": "5418bd48-df39-4579-8c47-e64a7819061a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Please show some of the train and test labels.**"
      ],
      "metadata": {
        "id": "kTPa7qVkfAsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[:5])\n",
        "print(test_labels[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTHU7PRufDYH",
        "outputId": "62ff5e90-1398-423a-8d3d-04a6707d963b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 0 0 3 0]\n",
            "[9 2 1 1 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Please show the digital content of image index 5 in the training dataset.**"
      ],
      "metadata": {
        "id": "9_GBzxbYgHov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krtpfZksgMr-",
        "outputId": "209ed371-02c1-4674-9150-eebdbd483c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 189 206 187  32   0   0   0  26 217 226\n",
            "  196  11   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 192 227 234 243 230 147 239 242 234 218\n",
            "  209   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 173 225 215 233 254   0 194 240 217 221\n",
            "  190   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 139 229 212 226 255   0 162 255 213 226\n",
            "  200   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  98 232 211 215 249  46 162 246 214 230\n",
            "  186   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  70 228 213 220 224 252 239 219 217 231\n",
            "  171   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 222 214 218 216 210 215 217 202 224\n",
            "  172   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  24 254 214 210 211 214 215 212 203 221\n",
            "  167   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 254 216 215 217 217 216 216 206 225\n",
            "  150   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 247 216 214 217 216 214 212 203 226\n",
            "  136   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 245 216 214 216 217 215 211 204 225\n",
            "  125   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 247 216 214 217 220 217 213 203 222\n",
            "  147   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 248 216 215 218 222 216 214 207 218\n",
            "  179   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 249 216 217 219 222 217 214 210 215\n",
            "  211   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 255 214 218 219 224 218 215 211 211\n",
            "  231   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  79 227 209 219 219 227 219 215 213 206\n",
            "  254  58   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 146 226 211 220 219 228 218 215 216 205\n",
            "  219 163   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 202 221 214 221 219 231 218 215 218 213\n",
            "  212 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 234 217 216 220 219 234 217 215 218 216\n",
            "  223 247   7   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  17 254 212 219 219 220 233 214 216 219 222\n",
            "  153 238  58   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  66 255 208 220 219 222 241 220 218 218 218\n",
            "  192 242  99   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 142 235 203 218 216 231 242 225 233 219 214\n",
            "  216 238 144   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 177 248 227 229 211 255  76   0 247 243 230\n",
            "  230 249 187   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 101 241 228 228 220 255  64   0 243 237 230\n",
            "  227 241 142   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 242 222 218 255  62   0 223 238 225\n",
            "  238 255  31   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  45 255 242 235 255  84   0 246 255 242\n",
            "  255  70   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  61 102 168  25   0 139 161  74\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Please plot the image of the index 5 in the training dataset.**"
      ],
      "metadata": {
        "id": "ltmkv8CpgT_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(train_images[4])\n",
        "plt.title('Index 5 in the training dataset.')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "mm93-79rgWVB",
        "outputId": "635ab55b-ba27-44ab-eef0-be59120a4d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the label for the index 5 in the train_label and looking up in the above list, what does it mean?**"
      ],
      "metadata": {
        "id": "A1rN_pjjgtVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = train_labels[4]\n",
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTS6EAnsgwPP",
        "outputId": "0815d02a-4de7-4fe5-9d84-d9734c62abb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** \\\n",
        "As the class labels are:\n",
        "\n",
        "0. T-shirt/top\n",
        "\n",
        "1. Trouser\n",
        "\n",
        "2. Pullover\n",
        "\n",
        "3. Dress\n",
        "\n",
        "4. Coat\n",
        "\n",
        "5. Sandal\n",
        "\n",
        "6. Shirt\n",
        "\n",
        "7. Sneaker\n",
        "\n",
        "8. Bag\n",
        "\n",
        "9. Ankle boot\n",
        "\n",
        "It means that the image at index 5 is a T-shirt/top.\n",
        "\n"
      ],
      "metadata": {
        "id": "xSdv97mmjSNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Please show the digital content of image index 500 in the testing dataset.**"
      ],
      "metadata": {
        "id": "a74q_65-lnxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_images[499])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um-YbKvthnn7",
        "outputId": "4dd88550-ffce-42ca-fb9b-861f3a5627b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0  40   0   0   0   0   0   0   0  26\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 213 250 196  47  17   2   4   8 181 236\n",
            "  204   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 189 236 238 254 246 255 255 241 240 226\n",
            "  243  35   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 228 235 221 225 234 215 227 227 225 224\n",
            "  246  71   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 252 232 226 226 222 232 225 225 233 227\n",
            "  245 146   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 227 228 226 227 226 226 238 229 220\n",
            "  241 224   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   3 255 226 227 228 228 228 232 226 137 130\n",
            "  216 255   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  22 255 227 228 227 226 226 235 217 139 130\n",
            "  210 235   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  59 255 226 230 229 229 229 229 242 212 207\n",
            "  233 237  13   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  83 255 227 230 229 229 229 228 228 241 237\n",
            "  241 219   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 226 230 229 229 229 229 229 231 226\n",
            "  251 150   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 230 229 229 229 229 229 228 233 228\n",
            "  249 136   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  29 255 228 230 230 230 230 230 230 230 231\n",
            "  248 155   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  34 255 229 232 231 231 231 231 232 230 230\n",
            "  250 152   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  13 255 229 231 231 231 231 231 231 230 229\n",
            "  251 135   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 255 231 231 231 231 231 231 231 231 228\n",
            "  252 125   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  12 255 231 231 231 231 231 231 231 232 226\n",
            "  252 130   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  26 255 228 232 231 231 231 231 231 233 226\n",
            "  251 135   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  32 255 228 232 231 231 231 231 231 233 226\n",
            "  249 139   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  26 255 227 231 231 232 231 231 231 233 227\n",
            "  247 139   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  22 255 223 231 231 231 231 231 231 233 227\n",
            "  248 127   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  29 255 225 231 231 232 231 231 231 233 227\n",
            "  248 124   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 255 223 232 232 232 232 232 231 233 227\n",
            "  247 130   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 255 223 232 232 232 232 232 230 233 227\n",
            "  246 134   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  54 255 228 232 232 233 233 233 232 233 227\n",
            "  247 131   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  44 235 224 228 224 225 222 222 223 223 224\n",
            "  244 130   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  38 255 242 255 255 255 255 255 255 255 238\n",
            "  255 144   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   2 131  97 106 106 106 106 106 106 106 100\n",
            "  137  54   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Please plot the image of the index 500 in the testing dataset.**"
      ],
      "metadata": {
        "id": "k7Q0qKlYh8We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(test_images[499])\n",
        "plt.title('Index 500 in the testing dataset.')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_hcRvlPNiSIw",
        "outputId": "568a16d5-a909-4ee2-d6ab-45d9d89cabee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is the label for the index 500 in the test_label and looking up in the above list, what does it mean?**"
      ],
      "metadata": {
        "id": "R3sg3hSJjw1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_test = test_labels[499]\n",
        "print(label_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbNW5THuj-TN",
        "outputId": "76cc50de-8f75-4f72-ec6f-6fb29a0d1e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** \\\n",
        "As the class labels are:\n",
        "\n",
        "0. T-shirt/top\n",
        "\n",
        "1. Trouser\n",
        "\n",
        "2. Pullover\n",
        "\n",
        "3. Dress\n",
        "\n",
        "4. Coat\n",
        "\n",
        "5. Sandal\n",
        "\n",
        "6. Shirt\n",
        "\n",
        "7. Sneaker\n",
        "\n",
        "8. Bag\n",
        "\n",
        "9. Ankle boot\n",
        "\n",
        "It means that the image at index 5 is a T-shirt/top. It is similar to question 6, differentiating between train_labels and test_labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "TteJbdmvkuEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Please import models and layers from the Keras library**"
      ],
      "metadata": {
        "id": "wTPJg9E_mDcl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "993383c2"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Define a sequential model and call it myNetwork.**"
      ],
      "metadata": {
        "id": "LEp-_5jVot0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myNetwork = models.Sequential()"
      ],
      "metadata": {
        "id": "en645IBso0mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Reshape the images from 28x28 to one column with 784 neurons (flattening).**"
      ],
      "metadata": {
        "id": "5vnZB5BKo4Y0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a27d3503",
        "outputId": "c0397c76-7763-4db3-be81-4312869070b1"
      },
      "source": [
        "myNetwork.add(layers.Flatten(input_shape=(28, 28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Also, please normalize the image by dividing teh image by 255**"
      ],
      "metadata": {
        "id": "DGjxCboMpQxo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLcoL_N9paUA",
        "outputId": "dc629c78-ab2b-4b19-d853-4b6486fd1655"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(\"Train images normalized.\")\n",
        "print(\"Test images normalized.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images normalized.\n",
            "Test images normalized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Add one hidden layer that has 512 neurons, using the 'relu' activation function.**"
      ],
      "metadata": {
        "id": "WWbBWZk2pgDv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30d0023"
      },
      "source": [
        "myNetwork.add(layers.Dense(512, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Add one hidden layer that has 128 neurons, using the 'relu' activation function.**"
      ],
      "metadata": {
        "id": "7LVFbkNvqMCM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c31b748"
      },
      "source": [
        "myNetwork.add(layers.Dense(128, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Add the last layer as a 10-neuron dense layer that uses the 'softmax' as the activation function. Why do we use softmax for the lat layer? How does it work under the hood? Make sure to explain this in your video.**"
      ],
      "metadata": {
        "id": "Vd4nxI3zqZP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myNetwork.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "w5J5FASQrvsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960dc89c"
      },
      "source": [
        "**Answer:** \\\n",
        "We use softmax for multi-class classification in the output layer. It works converting raw scores into a probability distribution, where each output represents the likelihood of the input belonging to a specific class, and all probabilities sum to 1, helping in making a clear class prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Use the following two settings for the compiler and run them separately and see what the differences are.**\n",
        "\n",
        "**a. Option A:** \\\n",
        "  **i. Optimizer:** adam \\\n",
        "  **ii. loss:** 'sparse_categorical_crossentropy'' \\\n",
        "  **iii. Metrics:** ['accuracy'] \\ \\\n",
        "  \\\n",
        "**b. Option B:** \\\n",
        "  **i. Optimizer:** rmsprop \\\n",
        "  **ii. loss:** 'categorical_crossentropy'' \\\n",
        "  **iii. Metrics:** ['accuracy']"
      ],
      "metadata": {
        "id": "W0-s69IVssxx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6831c9cf",
        "outputId": "850595ee-ed2f-4c5a-e411-3bfd82027c5a"
      },
      "source": [
        "myNetwork.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_A = myNetwork.fit(train_images, train_labels, epochs=5, validation_split=0.2)\n",
        "\n",
        "test_loss_A, test_acc_A = myNetwork.evaluate(test_images, test_labels)\n",
        "print(\"{:.4f}\".format(test_loss_A))\n",
        "print(\"{:.4f}\".format(test_acc_A))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8955 - loss: 0.3145 - val_accuracy: 0.8753 - val_loss: 0.3851\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9007 - loss: 0.2986 - val_accuracy: 0.8690 - val_loss: 0.3948\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9049 - loss: 0.2851 - val_accuracy: 0.8838 - val_loss: 0.3598\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2651 - val_accuracy: 0.8835 - val_loss: 0.3528\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.2609 - val_accuracy: 0.8843 - val_loss: 0.3499\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.3704\n",
            "0.3722\n",
            "0.8814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a07a2fb8",
        "outputId": "d04b5f7e-94ea-46ed-dc9f-ffe45fd25ae3"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "myNetwork_B = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "myNetwork_B.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_B = myNetwork_B.fit(train_images, train_labels_one_hot, epochs=5, validation_split=0.2)\n",
        "\n",
        "test_loss_B, test_acc_B = myNetwork_B.evaluate(test_images, test_labels_one_hot)\n",
        "print(\"{:.4f}\".format(test_loss_B))\n",
        "print(\"{:.4f}\".format(test_acc_B))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.7646 - loss: 0.6578 - val_accuracy: 0.8401 - val_loss: 0.4518\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8600 - loss: 0.3902 - val_accuracy: 0.8517 - val_loss: 0.4091\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.3685 - val_accuracy: 0.8687 - val_loss: 0.3758\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8779 - loss: 0.3467 - val_accuracy: 0.8719 - val_loss: 0.3815\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8838 - loss: 0.3313 - val_accuracy: 0.8729 - val_loss: 0.4101\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.4316\n",
            "0.4366\n",
            "0.8615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7093422"
      },
      "source": [
        "**Diferences:** \\\n",
        "Option A uses adam with sparse_categorical_crossentropy (integer labels), resulting in slightly better performance (loss: 0.3939, acc: 0.8714).\n",
        "Option B uses rmsprop with categorical_crossentropy (one-hot encoded labels), with slightly lower performance (loss: 0.4165, acc: 0.8660).\n",
        "The main difference lies in the loss function and the need for one-hot encoding of labels for Option B."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Now after the compilation, please try to find the pattern using the fit command. Set the number of epochs to 10.**"
      ],
      "metadata": {
        "id": "6Gv5txii0Q2L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "320351ea",
        "outputId": "4db88cc3-6cc8-4878-a17a-9e33b7f21786"
      },
      "source": [
        "myNetwork_18A = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "myNetwork_18A.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_18A = myNetwork_18A.fit(train_images, train_labels, epochs=10, validation_split=0.2)\n",
        "\n",
        "test_loss_18A, test_acc_18A = myNetwork_18A.evaluate(test_images, test_labels)\n",
        "print(\"{:.4f}\".format(test_loss_18A))\n",
        "print(\"{:.4f}\".format(test_acc_18A))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7807 - loss: 0.6130 - val_accuracy: 0.8484 - val_loss: 0.4219\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8583 - loss: 0.3809 - val_accuracy: 0.8703 - val_loss: 0.3484\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8772 - loss: 0.3294 - val_accuracy: 0.8727 - val_loss: 0.3510\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8872 - loss: 0.3041 - val_accuracy: 0.8706 - val_loss: 0.3652\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.8949 - loss: 0.2833 - val_accuracy: 0.8825 - val_loss: 0.3322\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8998 - loss: 0.2665 - val_accuracy: 0.8837 - val_loss: 0.3257\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9034 - loss: 0.2557 - val_accuracy: 0.8829 - val_loss: 0.3189\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9084 - loss: 0.2395 - val_accuracy: 0.8879 - val_loss: 0.3247\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9124 - loss: 0.2310 - val_accuracy: 0.8829 - val_loss: 0.3297\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9162 - loss: 0.2219 - val_accuracy: 0.8844 - val_loss: 0.3390\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3583\n",
            "0.3698\n",
            "0.8809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bdfa8ec",
        "outputId": "a63de556-fd54-4209-c055-9f6f7250d5c4"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "if 'train_labels_one_hot' not in locals() or 'test_labels_one_hot' not in locals():\n",
        "    train_labels_one_hot = to_categorical(train_labels)\n",
        "    test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "myNetwork_18B = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "myNetwork_18B.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_18B = myNetwork_18B.fit(train_images, train_labels_one_hot, epochs=10, validation_split=0.2)\n",
        "\n",
        "test_loss_18B, test_acc_18B = myNetwork_18B.evaluate(test_images, test_labels_one_hot)\n",
        "print(\"{:.4f}\".format(test_loss_18B))\n",
        "print(\"{:.4f}\".format(test_acc_18B))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.7568 - loss: 0.6578 - val_accuracy: 0.8483 - val_loss: 0.4259\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.8570 - loss: 0.3989 - val_accuracy: 0.8601 - val_loss: 0.4181\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8743 - loss: 0.3603 - val_accuracy: 0.8550 - val_loss: 0.4125\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8774 - loss: 0.3421 - val_accuracy: 0.8729 - val_loss: 0.3871\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8805 - loss: 0.3357 - val_accuracy: 0.8699 - val_loss: 0.4311\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8865 - loss: 0.3228 - val_accuracy: 0.8805 - val_loss: 0.3800\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8879 - loss: 0.3099 - val_accuracy: 0.8794 - val_loss: 0.3748\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8901 - loss: 0.3140 - val_accuracy: 0.8835 - val_loss: 0.4022\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8911 - loss: 0.3046 - val_accuracy: 0.8680 - val_loss: 0.4277\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.3020 - val_accuracy: 0.8798 - val_loss: 0.4043\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.4313\n",
            "0.4395\n",
            "0.8691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. How do you compare the fashion_MNIST with what we learned in the class using the MNIST? Explain in your video.**"
      ],
      "metadata": {
        "id": "0VCozFi-8RcZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1fc3c7"
      },
      "source": [
        "Both are 28x28 grayscale image datasets with 10 classes for classification, used as benchmarks in machine learning.\n",
        "MNIST contains handwritten digits (0-9), while Fashion MNIST features clothing items (shirts, trousers, etc.).\n",
        "Fashion MNIST is considered a more challenging task than MNIST, as clothing classes can be visually harder to distinguish.\n",
        "This complexity makes it a good replacement for MNIST in evaluating models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What can we infer from the differences in the accuracy? What could be the reasons for that? Explain in your video.**"
      ],
      "metadata": {
        "id": "ZfWcQPXxBwQP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb936f18"
      },
      "source": [
        "The accuracy differences the impact of optimizer choice on model performance. Option A, with Adam, generally achieved slightly higher test accuracy than Option B with RMSprop. This happens because different optimizers handle learning rates and gradient updates distinctly, influencing their convergence and ability to find an optimal solution for the given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. Use the evaluate() function from the Keras library to calculate the achieved accuracy and loss over the test images and labels. Do we have overfitting? Explain in your video.**"
      ],
      "metadata": {
        "id": "iJtQtYGfCG0-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fc071e3",
        "outputId": "c53ead04-ce5c-4b58-972d-d24bafffa48e"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "loss_18A_eval, acc_18A_eval = myNetwork_18A.evaluate(test_images, test_labels, verbose=0)\n",
        "print(\"18 A: \")\n",
        "print(f\" Test Loss: {loss_18A_eval:.4f}\")\n",
        "print(f\" Test Accuracy: {acc_18A_eval:.4f}\")\n",
        "\n",
        "if 'test_labels_one_hot' not in locals():\n",
        "    test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "print(f\" Train Loss: {history_18A.history['loss'][-1]:.4f}\")\n",
        "print(f\" Train Acc: {history_18A.history['accuracy'][-1]:.4f}\")\n",
        "print(f\" Validation Loss: {history_18A.history['val_loss'][-1]:.4f}\")\n",
        "print(f\" Validation Acc: {history_18A.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        "loss_18B_eval, acc_18B_eval = myNetwork_18B.evaluate(test_images, test_labels_one_hot, verbose=0)\n",
        "print(\"\\n18 B: \")\n",
        "print(f\" Test Loss: {loss_18B_eval:.4f}\")\n",
        "print(f\" Test Accuracy: {acc_18B_eval:.4f}\")\n",
        "\n",
        "print(f\" Train Loss: {history_18B.history['loss'][-1]:.4f}\")\n",
        "print(f\" Train Acc: {history_18B.history['accuracy'][-1]:.4f}\")\n",
        "print(f\" Validation Loss: {history_18B.history['val_loss'][-1]:.4f}\")\n",
        "print(f\" Validation Acc: {history_18B.history['val_accuracy'][-1]:.4f}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 A: \n",
            " Test Loss: 0.3698\n",
            " Test Accuracy: 0.8809\n",
            " Train Loss: 0.2227\n",
            " Train Acc: 0.9157\n",
            " Validation Loss: 0.3390\n",
            " Validation Acc: 0.8844\n",
            "\n",
            "18 B: \n",
            " Test Loss: 0.4395\n",
            " Test Accuracy: 0.8691\n",
            " Train Loss: 0.3048\n",
            " Train Acc: 0.8955\n",
            " Validation Loss: 0.4043\n",
            " Validation Acc: 0.8798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2afffa4"
      },
      "source": [
        "**Answer:** \\\n",
        "Both models (18A & 18B) show overfitting, as training accuracy (0.90-0.91) is significantly higher than test accuracy (~0.87-0.88), indicating poor generalization to unseen data.\n",
        "The lower training loss compared to test/validation loss further supports this, suggesting the models memorized training noise.\n",
        "Model 18A shows slightly less overfitting than 18B, but both could benefit from regularization techniques."
      ]
    }
  ]
}